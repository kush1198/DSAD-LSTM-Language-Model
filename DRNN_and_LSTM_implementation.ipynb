{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "nlp-sequence-models",
      "graded_item_id": "xxuVc",
      "launcher_item_id": "X20PE"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "DRNN and LSTM implementation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaMWDXU2RLsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from rnn_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyRyBhcnRLsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_cell_forward(xt, a_prev, parameters):\n",
        "    \"\"\"   Implements a single forward step of the RNN-cell as described in Figure (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    Wax = parameters[\"Wax\"]\n",
        "    Waa = parameters[\"Waa\"]\n",
        "    Wya = parameters[\"Wya\"]\n",
        "    ba = parameters[\"ba\"]\n",
        "    by = parameters[\"by\"]\n",
        "    \n",
        "\n",
        "    a_next = None\n",
        "    yt_pred = None   \n",
        "    cache = (a_next, a_prev, xt, parameters)\n",
        "    \n",
        "    return a_next, yt_pred, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtD68aTkRLsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "xt_tmp = np.random.randn(3,10)\n",
        "a_prev_tmp = np.random.randn(5,10)\n",
        "parameters_tmp = {}\n",
        "parameters_tmp['Waa'] = np.random.randn(5,5)\n",
        "parameters_tmp['Wax'] = np.random.randn(5,3)\n",
        "parameters_tmp['Wya'] = np.random.randn(2,5)\n",
        "parameters_tmp['ba'] = np.random.randn(5,1)\n",
        "parameters_tmp['by'] = np.random.randn(2,1)\n",
        "\n",
        "a_next_tmp, yt_pred_tmp, cache_tmp = rnn_cell_forward(xt_tmp, a_prev_tmp, parameters_tmp)\n",
        "print(\"a_next[4] = \\n\", a_next_tmp[4])\n",
        "print(\"a_next.shape = \\n\", a_next_tmp.shape)\n",
        "print(\"yt_pred[1] =\\n\", yt_pred_tmp[1])\n",
        "print(\"yt_pred.shape = \\n\", yt_pred_tmp.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqzI8eHLRLsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def lstm_forward(x, a0, parameters):\n",
        "    \"\"\"Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (4).\n",
        "    \"\"\"\n",
        "\n",
        "    caches = []\n",
        "    \n",
        "    Wy = parameters['Wy'] \n",
        "    n_x, m, T_x = None\n",
        "    n_y, n_a = None\n",
        "    \n",
        "    a = None\n",
        "    c = None\n",
        "    y = None\n",
        "    \n",
        "    a_next = None\n",
        "    c_next = None\n",
        "    \n",
        "    for t in range(None):\n",
        "        xt = None\n",
        "        a_next, c_next, yt, cache = None\n",
        "        a[:,:,t] = None\n",
        "        c[:,:,t]  = None\n",
        "        y[:,:,t] = None\n",
        "        None\n",
        "\n",
        "    caches = (caches, x)\n",
        "\n",
        "    return a, y, c, caches\n",
        "\n",
        "np.random.seed(1)\n",
        "x_tmp = np.random.randn(3,10,7)\n",
        "a0_tmp = np.random.randn(5,10)\n",
        "parameters_tmp = {}\n",
        "parameters_tmp['Wf'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bf'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wi'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bi']= np.random.randn(5,1)\n",
        "parameters_tmp['Wo'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bo'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wc'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bc'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wy'] = np.random.randn(2,5)\n",
        "parameters_tmp['by'] = np.random.randn(2,1)\n",
        "\n",
        "a_tmp, y_tmp, c_tmp, caches_tmp = lstm_forward(x_tmp, a0_tmp, parameters_tmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sybEf3CMRLtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_cell_backward(da_next, dc_next, cache):\n",
        "    \"\"\"Implement the backward pass for the LSTM-cell (single time-step).\n",
        "    \"\"\"\n",
        "\n",
        "    (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache\n",
        "    n_x, m = None\n",
        "    n_a, m = None\n",
        "    dot = None\n",
        "    dcct = None\n",
        "    dit = None\n",
        "    dft = None\n",
        "    dit = None\n",
        "    dft = None\n",
        "    dot = None\n",
        "    dcct = None\n",
        "    dWf = None\n",
        "    dWi = None\n",
        "    dWc = None\n",
        "    dWo = None\n",
        "    dbf = None\n",
        "    dbi = None\n",
        "    dbc = None\n",
        "    dbo = None\n",
        "    da_prev = None\n",
        "    dc_prev = None\n",
        "    dxt = None\n",
        "    \n",
        "    gradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dc_prev\": dc_prev, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
        "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo}\n",
        "\n",
        "    return gradients\n",
        "    \n",
        "np.random.seed(1)\n",
        "xt_tmp = np.random.randn(3,10)\n",
        "a_prev_tmp = np.random.randn(5,10)\n",
        "c_prev_tmp = np.random.randn(5,10)\n",
        "parameters_tmp = {}\n",
        "parameters_tmp['Wf'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bf'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wi'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bi'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wo'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bo'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wc'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bc'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wy'] = np.random.randn(2,5)\n",
        "parameters_tmp['by'] = np.random.randn(2,1)\n",
        "\n",
        "a_next_tmp, c_next_tmp, yt_tmp, cache_tmp = lstm_cell_forward(xt_tmp, a_prev_tmp, c_prev_tmp, parameters_tmp)\n",
        "\n",
        "da_next_tmp = np.random.randn(5,10)\n",
        "dc_next_tmp = np.random.randn(5,10)\n",
        "gradients_tmp = lstm_cell_backward(da_next_tmp, dc_next_tmp, cache_tmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0meSRmqRLtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_backward(da, caches):\n",
        "    \n",
        "    \"\"\" Implement the backward pass for the RNN with LSTM-cell (over a whole sequence).\n",
        "    \"\"\"\n",
        "\n",
        "    (caches, x) = caches\n",
        "    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0]\n",
        "  \n",
        "    n_a, m, T_x = None\n",
        "    n_x, m = None\n",
        "    dx = None\n",
        "    da0 = None\n",
        "    da_prevt = None\n",
        "    dc_prevt = None\n",
        "    dWf = None\n",
        "    dWi = None\n",
        "    dWc = None\n",
        "    dWo = None\n",
        "    dbf = None\n",
        "    dbi = None\n",
        "    dbc = None\n",
        "    dbo = None\n",
        "    \n",
        "    for t in reversed(range(None)):\n",
        "        gradients = None\n",
        "        dx[:,:,t] = None\n",
        "        dWf = None\n",
        "        dWi = None\n",
        "        dWc = None\n",
        "        dWo = None\n",
        "        dbf = None\n",
        "        dbi = None\n",
        "        dbc = None\n",
        "        dbo = None\n",
        "    da0 = None\n",
        "    \n",
        "    gradients = {\"dx\": dx, \"da0\": da0, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
        "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo}\n",
        "    \n",
        "    return gradients\n",
        "\n",
        "np.random.seed(1)\n",
        "x_tmp = np.random.randn(3,10,7)\n",
        "a0_tmp = np.random.randn(5,10)\n",
        "\n",
        "parameters_tmp = {}\n",
        "parameters_tmp['Wf'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bf'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wi'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bi'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wo'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bo'] = np.random.randn(5,1)\n",
        "parameters_tmp['Wc'] = np.random.randn(5, 5+3)\n",
        "parameters_tmp['bc'] = np.random.randn(5,1)\n",
        "\n",
        "a_tmp, y_tmp, c_tmp, caches_tmp = lstm_forward(x_tmp, a0_tmp, parameters_tmp)\n",
        "\n",
        "da_tmp = np.random.randn(5, 10, 4)\n",
        "gradients_tmp = lstm_backward(da_tmp, caches_tmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}